{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dutch-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_start_time = time.time()\n",
    "df_train = pd.read_csv('../../dataset/meal_service/train.csv')\n",
    "df_test = pd.read_csv('../../dataset/meal_service/test.csv')\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "NUM_VECTORS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_holiday_lists(df):\n",
    "    # pre-processing    \n",
    "    is_yesterday_holiday_list = []\n",
    "    is_tomorrow_holiday_list = []\n",
    "\n",
    "    for i in range (0, len(df)):\n",
    "        if df.iloc[i]['요일'] == '월':\n",
    "            is_yesterday_holiday_list.append(1)\n",
    "            if i < len(df)-1:\n",
    "                is_tomorrow_holiday_list.append(0) if df.iloc[i+1]['요일'] == '화' else is_tomorrow_holiday_list.append(1)\n",
    "            else:\n",
    "                is_tomorrow_holiday_list.append(0)\n",
    "        elif df.iloc[i]['요일'] == '화':\n",
    "            if i < len(df)-1:\n",
    "                is_tomorrow_holiday_list.append(0) if df.iloc[i+1]['요일'] == '수' else is_tomorrow_holiday_list.append(1)\n",
    "            else:\n",
    "                is_tomorrow_holiday_list.append(0)\n",
    "            if i > 0:\n",
    "                is_yesterday_holiday_list.append(0) if df.iloc[i-1]['요일'] == '월' else is_yesterday_holiday_list.append(1)\n",
    "            else:\n",
    "                is_yesterday_holiday_list.append(0)\n",
    "        elif df.iloc[i]['요일'] == '수':\n",
    "            if i < len(df)-1:\n",
    "                is_tomorrow_holiday_list.append(0) if df.iloc[i+1]['요일'] == '목' else is_tomorrow_holiday_list.append(1)\n",
    "            else:\n",
    "                is_tomorrow_holiday_list.append(0)\n",
    "            if i > 0:\n",
    "                is_yesterday_holiday_list.append(0) if df.iloc[i-1]['요일'] == '화' else is_yesterday_holiday_list.append(1)\n",
    "            else:\n",
    "                is_yesterday_holiday_list.append(0)\n",
    "        elif df.iloc[i]['요일'] == '목':\n",
    "            if i < len(df)-1:\n",
    "                is_tomorrow_holiday_list.append(0) if df.iloc[i+1]['요일'] == '금' else is_tomorrow_holiday_list.append(1)\n",
    "            else:\n",
    "                is_tomorrow_holiday_list.append(0)\n",
    "            if i > 0:\n",
    "                is_yesterday_holiday_list.append(0) if df.iloc[i-1]['요일'] == '수' else is_yesterday_holiday_list.append(1)\n",
    "            else:\n",
    "                is_yesterday_holiday_list.append(0)\n",
    "        elif df.iloc[i]['요일'] == '금':\n",
    "            is_tomorrow_holiday_list.append(1)\n",
    "            if i > 0:\n",
    "                is_yesterday_holiday_list.append(0) if df.iloc[i-1]['요일'] == '목' else is_yesterday_holiday_list.append(1)\n",
    "            else:\n",
    "                is_yesterday_holiday_list.append(0)\n",
    "                \n",
    "    return is_yesterday_holiday_list, is_tomorrow_holiday_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qualified-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "\n",
    "def get_is_corona_list(df):\n",
    "    corona_list = []\n",
    "    corona_start = arrow.get('2020-03-01')\n",
    "    for i in range(0, len(df)):\n",
    "        date = arrow.get(df.iloc[i]['일자'])\n",
    "        if date >= corona_start:\n",
    "            corona_list.append(1)\n",
    "        else:\n",
    "            corona_list.append(0)\n",
    "    \n",
    "    return corona_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "commercial-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_wed_of_month(date):\n",
    "    curr = arrow.get(date)\n",
    "    if curr.weekday() != 2:\n",
    "        # not wednesday\n",
    "        return False\n",
    "    else:\n",
    "        curr_month = curr.month\n",
    "        if curr_month != curr.shift(days=7).month:\n",
    "            # last wednesday of the month\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "def get_is_last_wed_list(df):\n",
    "    is_last_wed_list = []\n",
    "    for i in range(0, len(df)):\n",
    "        date = df.iloc[i]['일자']\n",
    "        if is_last_wed_of_month(date):\n",
    "            is_last_wed_list.append(1)\n",
    "        else:\n",
    "            is_last_wed_list.append(0)\n",
    "    \n",
    "    return is_last_wed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regular-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_list(df):\n",
    "    month_list = []\n",
    "    for i in range(0, len(df)):\n",
    "        month = arrow.get(df.iloc[i]['일자']).month\n",
    "        month_list.append(month)\n",
    "    \n",
    "    return month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecological-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_list(df):\n",
    "    day_list = []\n",
    "    for i in range(0, len(df)):\n",
    "        day = arrow.get(df.iloc[i]['일자']).day\n",
    "        day_list.append(day)\n",
    "    \n",
    "    return day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amateur-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_and_processing_menu_str(menu_row):\n",
    "    # split by space\n",
    "    splits = menu_row.split(' ')\n",
    "    menu = []\n",
    "    is_new_menu = False\n",
    "    for dish in splits:\n",
    "        if len(dish) > 1:\n",
    "            # find (New)\n",
    "            if '(New)' in dish:\n",
    "                menu.append(dish.split('(New)')[0] + dish.split('(New)')[1])\n",
    "                is_new_menu = True\n",
    "            elif '(' not in dish and ')' not in dish:\n",
    "                menu.append(dish)\n",
    "    if len(menu) <= 3:\n",
    "        # no menu today\n",
    "        menu = ['-']\n",
    "    \n",
    "    return menu, is_new_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "least-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_menu_info(df):\n",
    "    is_new_lunch_menu = []\n",
    "    is_new_dinner_menu = []\n",
    "    lunch_menus = []\n",
    "    dinner_menus = []\n",
    "    for i in range(0, len(df)):\n",
    "        row_lunch = df.iloc[i]['중식메뉴']\n",
    "        row_dinner = df.iloc[i]['석식메뉴']\n",
    "        \n",
    "        lunch_menu, new_lunch_menu = seperate_and_processing_menu_str(row_lunch)\n",
    "        is_new_lunch_menu.append(1) if new_lunch_menu else is_new_lunch_menu.append(0)\n",
    "        \n",
    "        dinner_menu, new_dinner_menu = seperate_and_processing_menu_str(row_dinner)\n",
    "        is_new_dinner_menu.append(1) if new_dinner_menu else is_new_dinner_menu.append(0)\n",
    "\n",
    "        lunch_menus.append(lunch_menu)\n",
    "        dinner_menus.append(dinner_menu)\n",
    "    \n",
    "    return is_new_lunch_menu, is_new_dinner_menu, lunch_menus, dinner_menus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defensive-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_no_dinner_list(df):\n",
    "    is_no_dinner_list = []\n",
    "    for i in range(0, len(df)):\n",
    "        is_no_dinner_list.append(1) if len(df.iloc[i]['석식메뉴']) <= 20 else is_no_dinner_list.append(0)\n",
    "    \n",
    "    return is_no_dinner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "single-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu_to_vectors(model, menus):\n",
    "    soups = []\n",
    "    mains = []\n",
    "    sides1 = []\n",
    "    sides2 = []\n",
    "    for menu in menus:\n",
    "        if len(menu) > 4:\n",
    "            soup = menu[1]\n",
    "            main = menu[2]\n",
    "            side1 = menu[3]\n",
    "            side2 = menu[4]\n",
    "            \n",
    "            vector1 = model.wv.get_vector(soup)\n",
    "            vector2 = model.wv.get_vector(main)\n",
    "            vector3 = model.wv.get_vector(side1)\n",
    "            vector4 = model.wv.get_vector(side2)\n",
    "            \n",
    "            soups.append(vector1)\n",
    "            mains.append(vector2)\n",
    "            sides1.append(vector3)\n",
    "            sides2.append(vector4)\n",
    "        else:\n",
    "            zeros1 = np.zeros(NUM_VECTORS)\n",
    "            zeros2 = np.zeros(NUM_VECTORS)\n",
    "            zeros3 = np.zeros(NUM_VECTORS)\n",
    "            zeros4 = np.zeros(NUM_VECTORS)\n",
    "\n",
    "            soups.append(zeros1)\n",
    "            mains.append(zeros2)\n",
    "            sides1.append(zeros3)\n",
    "            sides2.append(zeros4)\n",
    "\n",
    "    \n",
    "    return soups, mains, sides1, sides2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advance-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_menus(df):\n",
    "    menus = []\n",
    "    for i in range(0, len(df)):\n",
    "        row_lunch = df.iloc[i]['중식메뉴']\n",
    "        row_dinner = df.iloc[i]['석식메뉴']\n",
    "        \n",
    "        lunch_menu, new_lunch_menu = seperate_and_processing_menu_str(row_lunch)\n",
    "        dinner_menu, new_dinner_menu = seperate_and_processing_menu_str(row_dinner)\n",
    "        \n",
    "        if len(lunch_menu) > 1:\n",
    "            menus.append(lunch_menu)\n",
    "        if len(dinner_menu) > 1:\n",
    "            menus.append(dinner_menu) \n",
    "            \n",
    "    return list(menus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automated-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2vector\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "try:\n",
    "    model = Word2Vec.load('food_embedding_%s.model' % NUM_VECTORS)\n",
    "    print('Model loaded')\n",
    "except:\n",
    "    print('Training word2vector')\n",
    "    menus = get_menus(df_all)\n",
    "    model = Word2Vec(sentences=menus, vector_size=NUM_VECTORS, window=7, min_count=0, workers=4, sg=0, epochs=5000)\n",
    "    model.save('food_embedding_%s.model' % NUM_VECTORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "artistic-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df, model):\n",
    "    yesterday_holiday_list, tommorow_holiday_list = get_is_holiday_lists(df)\n",
    "    is_corona_list = get_is_corona_list(df)\n",
    "    month_list = get_month_list(df)\n",
    "    day_list = get_day_list(df)\n",
    "    is_no_dinner_list = get_is_no_dinner_list(df)\n",
    "    is_new_lunch_list, is_new_dinner_list, lunch_menus, dinner_menus = get_menu_info(df)\n",
    "    is_last_wed_list = get_is_last_wed_list(df)\n",
    "\n",
    "    is_yesterday_holiday = pd.DataFrame({'is_yesterday_holiday': yesterday_holiday_list})\n",
    "    is_tomorrow_holiday = pd.DataFrame({'is_tomorrow_holiday': tommorow_holiday_list})\n",
    "    is_corona = pd.DataFrame({'is_corona': is_corona_list})\n",
    "    month = pd.DataFrame({'month': month_list})\n",
    "    day = pd.DataFrame({'day': day_list})\n",
    "    no_dinner = pd.DataFrame({'no_dinner': is_no_dinner_list})\n",
    "    is_new_lunch = pd.DataFrame({'is_new_lunch': is_new_lunch_list})\n",
    "    is_new_dinner = pd.DataFrame({'is_new_dinner': is_new_dinner_list})\n",
    "    # is_last_wed = pd.DataFrame({'is_last_wed': is_last_wed_list})\n",
    "    \n",
    "    # using word2vec\n",
    "    lunch_soups_list, lunch_mains_list, lunch_sides1_list, lunch_sides2_list = menu_to_vectors(model, lunch_menus)\n",
    "    dinner_soups_list, dinner_mains_list, dinner_sides1_list, dinner_sides2_list = menu_to_vectors(model, dinner_menus)\n",
    "    \n",
    "    lunch_soups = pd.DataFrame({'lunch_soups': lunch_soups_list})\n",
    "    lunch_mains = pd.DataFrame({'lunch_mains': lunch_mains_list})\n",
    "    lunch_sides1 = pd.DataFrame({'lunch_sides1': lunch_sides1_list})\n",
    "    lunch_sides2 = pd.DataFrame({'lunch_sides2': lunch_sides2_list})\n",
    "    dinner_soups = pd.DataFrame({'dinner_soups': dinner_soups_list})\n",
    "    dinner_mains = pd.DataFrame({'dinner_mains': dinner_mains_list})\n",
    "    dinner_sides1 = pd.DataFrame({'dinner_sides1': dinner_sides1_list})\n",
    "    dinner_sides2 = pd.DataFrame({'dinner_sides2': dinner_sides2_list})\n",
    "\n",
    "    df = df.join(is_yesterday_holiday)\n",
    "    df = df.join(is_tomorrow_holiday)\n",
    "    df = df.join(is_corona)\n",
    "    df = df.join(month)\n",
    "    df = df.join(day)\n",
    "    df = df.join(no_dinner)\n",
    "    df = df.join(is_new_lunch)\n",
    "    df = df.join(is_new_dinner) \n",
    "\n",
    "    # 원핫인코딩\n",
    "    df = pd.get_dummies(df, columns=['요일'])\n",
    "    \n",
    "    dropped_df = df.loc[:, [col for col in df.columns if col not in ['일자', '조식메뉴', '중식메뉴', '석식메뉴', '석식계', '중식계']]]\n",
    "    arr = dropped_df.to_numpy()\n",
    "\n",
    "    arr = np.concatenate((arr, np.array(lunch_soups.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    arr = np.concatenate((arr, np.array(lunch_mains.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    arr = np.concatenate((arr, np.array(lunch_sides1.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    # arr = np.concatenate((arr, np.array(lunch_sides2.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    arr = np.concatenate((arr, np.array(dinner_soups.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    arr = np.concatenate((arr, np.array(dinner_mains.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    arr = np.concatenate((arr, np.array(dinner_sides1.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    # arr = np.concatenate((arr, np.array(dinner_sides2.to_numpy().tolist()).reshape(len(df),NUM_VECTORS)),axis=1)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "guilty-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "lunch_people = df_train['중식계']\n",
    "dinner_people = df_train['석식계']\n",
    "\n",
    "arr_train = pre_processing(df_train, model)\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(arr_train, lunch_people,\n",
    "                                                        random_state=random.randrange(1, 100))\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(arr_train, dinner_people,\n",
    "                                                        random_state=random.randrange(1, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sporting-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AutoML을 이용한 ML 구현\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "# suboptmal problem의 iteration 문제는 무시할 것! (suboptimal의 계산횟수를 한정하여 수렴시키겠다는 얘기)\n",
    "# 궁금하면 max_iter라는 값을 인자로 전달받는 ML 알고리즘을 살펴보세요!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 필요한 알고리즘을 불러와야 합니다!\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "# Ridge와 Lasso의 hyperparmeter: alpha\n",
    "# Logistic Regressio의 hyperparameter: penalty와 regularization strength인 C값\n",
    "from sklearn.svm import SVR\n",
    "# SVR의 hyperparameter: epsilon, regularization C, gamma, kernel = 'rbf', 'poly', 'sigmoid'\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# hidden_layer_sizes = (100,) , (10, 10, ) 정도만 activation = 'relu', 'logistic'까지만, alpha =0.0001, solver = 'lbfgs', 'adam'까지만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacterial-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', None), ('regressor', LinearRegression())])\n",
    "pre_list = [StandardScaler(), MinMaxScaler(), None]\n",
    "hyperparam_grid = [\n",
    "    {\"regressor\": [LinearRegression()], 'preprocessing': pre_list},\n",
    "    {\"regressor\": [Ridge()], 'preprocessing': pre_list,\n",
    "    \"regressor__alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
    "    {\"regressor\": [Lasso()], 'preprocessing': pre_list,\n",
    "    \"regressor__alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
    "    {\"regressor\": [LogisticRegression()], 'preprocessing': pre_list,\n",
    "    \"regressor__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
    "    {\"regressor\": [SVR()], 'preprocessing': pre_list,\n",
    "    \"regressor__epsilon\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"regressor__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
    "    {\"regressor\": [MLPRegressor()], 'preprocessing': pre_list,\n",
    "    \"regressor__hidden_layer_sizes\": [(100,) , (10, 10, )],\n",
    "    \"regressor__activation\": [\"relu\", \"logistic\"],\n",
    "    \"regressor__solver\": [\"lbfgs\", \"adam\"],\n",
    "    \"regressor__alpha\": [0.0001, 0.01, 1]}\n",
    "\n",
    "]\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "grid1 = GridSearchCV(pipe, hyperparam_grid, scoring='neg_mean_absolute_error',\n",
    "                     refit=True, cv=kfold)\n",
    "grid2 = GridSearchCV(pipe, hyperparam_grid, scoring='neg_mean_absolute_error',\n",
    "                     refit=True, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "subject-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid1 fitting time: 419.774486\n",
      "Pipeline(steps=[('preprocessing', MinMaxScaler()),\n",
      "                ('regressor', Lasso(alpha=1))])\n",
      "{'preprocessing': MinMaxScaler(), 'regressor': Lasso(alpha=1), 'regressor__alpha': 1}\n",
      "78.69324981198938\n",
      "71.7003295010078\n"
     ]
    }
   ],
   "source": [
    "grid1_start_time = time.time()\n",
    "grid1.fit(x1_train, y1_train)\n",
    "\n",
    "print('grid1 fitting time: %f' % (time.time() - grid1_start_time))\n",
    "print(grid1.best_estimator_)\n",
    "print(grid1.best_params_)\n",
    "print(-grid1.best_score_)\n",
    "print(-grid1.score(x1_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automatic-performance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid2 fitting time: 370.673415\n",
      "Pipeline(steps=[('preprocessing', MinMaxScaler()),\n",
      "                ('regressor', Lasso(alpha=1))])\n",
      "{'preprocessing': MinMaxScaler(), 'regressor': Lasso(alpha=1), 'regressor__alpha': 1}\n",
      "58.04685450331542\n",
      "54.36248685217784\n"
     ]
    }
   ],
   "source": [
    "grid2_start_time = time.time()\n",
    "grid2.fit(x2_train, y2_train)\n",
    "print('grid2 fitting time: %f' % (time.time() - grid2_start_time))\n",
    "print(grid2.best_estimator_)\n",
    "print(grid2.best_params_)\n",
    "print(-grid2.best_score_)\n",
    "print(-grid2.score(x2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "complimentary-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중식 최종 결과:  71.7003295010078\n",
      "석식 최종 결과:  54.36248685217784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print('중식 최종 결과: ', mean_absolute_error(y1_test, grid1.best_estimator_.predict(x1_test)))\n",
    "print('석식 최종 결과: ', mean_absolute_error(y2_test, grid2.best_estimator_.predict(x2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "biblical-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_date = pd.DataFrame(df_test['일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "metric-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_test = pre_processing(df_test, model)\n",
    "\n",
    "lunch_cnt_list = grid1.best_estimator_.predict(arr_test)\n",
    "dinner_cnt_list = grid2.best_estimator_.predict(arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pretty-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_lunch = pd.DataFrame({'중식계': lunch_cnt_list})\n",
    "df_result_dinner = pd.DataFrame({'석식계': dinner_cnt_list})\n",
    "df_result = df_result_date.join(df_result_lunch).join(df_result_dinner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "animal-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('../../dataset/meal_service/result.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "approved-cartoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>중식계</th>\n",
       "      <th>석식계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>959.225335</td>\n",
       "      <td>388.112314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>886.329593</td>\n",
       "      <td>459.041941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>645.181284</td>\n",
       "      <td>350.182151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1241.257655</td>\n",
       "      <td>531.750247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>1002.933100</td>\n",
       "      <td>501.302491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>965.892240</td>\n",
       "      <td>402.458448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>929.058657</td>\n",
       "      <td>485.056995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>689.072942</td>\n",
       "      <td>376.250962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>1249.137932</td>\n",
       "      <td>570.992061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>1004.839363</td>\n",
       "      <td>516.881701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>739.596803</td>\n",
       "      <td>330.153293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>1269.410617</td>\n",
       "      <td>587.170793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>1065.267859</td>\n",
       "      <td>591.417059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>965.990916</td>\n",
       "      <td>393.184236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>872.916067</td>\n",
       "      <td>512.755911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>648.192793</td>\n",
       "      <td>372.138003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>1224.060332</td>\n",
       "      <td>607.553080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>1007.856113</td>\n",
       "      <td>587.025667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>900.767763</td>\n",
       "      <td>394.688233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>869.014638</td>\n",
       "      <td>504.209212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>606.221861</td>\n",
       "      <td>352.044141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>1173.336637</td>\n",
       "      <td>586.777184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>962.843349</td>\n",
       "      <td>391.426810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>927.989971</td>\n",
       "      <td>553.572030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>693.028934</td>\n",
       "      <td>363.939858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>1308.367010</td>\n",
       "      <td>641.974384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>1104.236984</td>\n",
       "      <td>638.472412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>963.042091</td>\n",
       "      <td>382.241401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>910.463229</td>\n",
       "      <td>504.267070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>675.926026</td>\n",
       "      <td>353.409604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>1283.485001</td>\n",
       "      <td>611.490786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>1029.625200</td>\n",
       "      <td>535.180740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>947.742536</td>\n",
       "      <td>383.400628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>875.702065</td>\n",
       "      <td>480.292052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>663.871355</td>\n",
       "      <td>339.274249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>1231.065855</td>\n",
       "      <td>568.662011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>991.792657</td>\n",
       "      <td>545.851384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>885.761741</td>\n",
       "      <td>384.011950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>817.815692</td>\n",
       "      <td>456.586698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>599.150994</td>\n",
       "      <td>348.506375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>1206.596062</td>\n",
       "      <td>543.502074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>988.283662</td>\n",
       "      <td>524.886447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>906.483229</td>\n",
       "      <td>378.173363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>840.787280</td>\n",
       "      <td>445.886445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>615.540306</td>\n",
       "      <td>343.082918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>1219.861195</td>\n",
       "      <td>559.839392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>1030.710767</td>\n",
       "      <td>533.615448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>915.428950</td>\n",
       "      <td>391.995857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>892.471322</td>\n",
       "      <td>474.437133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>613.628739</td>\n",
       "      <td>356.722250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            일자          중식계         석식계\n",
       "0   2021-01-27   959.225335  388.112314\n",
       "1   2021-01-28   886.329593  459.041941\n",
       "2   2021-01-29   645.181284  350.182151\n",
       "3   2021-02-01  1241.257655  531.750247\n",
       "4   2021-02-02  1002.933100  501.302491\n",
       "5   2021-02-03   965.892240  402.458448\n",
       "6   2021-02-04   929.058657  485.056995\n",
       "7   2021-02-05   689.072942  376.250962\n",
       "8   2021-02-08  1249.137932  570.992061\n",
       "9   2021-02-09  1004.839363  516.881701\n",
       "10  2021-02-10   739.596803  330.153293\n",
       "11  2021-02-15  1269.410617  587.170793\n",
       "12  2021-02-16  1065.267859  591.417059\n",
       "13  2021-02-17   965.990916  393.184236\n",
       "14  2021-02-18   872.916067  512.755911\n",
       "15  2021-02-19   648.192793  372.138003\n",
       "16  2021-02-22  1224.060332  607.553080\n",
       "17  2021-02-23  1007.856113  587.025667\n",
       "18  2021-02-24   900.767763  394.688233\n",
       "19  2021-02-25   869.014638  504.209212\n",
       "20  2021-02-26   606.221861  352.044141\n",
       "21  2021-03-02  1173.336637  586.777184\n",
       "22  2021-03-03   962.843349  391.426810\n",
       "23  2021-03-04   927.989971  553.572030\n",
       "24  2021-03-05   693.028934  363.939858\n",
       "25  2021-03-08  1308.367010  641.974384\n",
       "26  2021-03-09  1104.236984  638.472412\n",
       "27  2021-03-10   963.042091  382.241401\n",
       "28  2021-03-11   910.463229  504.267070\n",
       "29  2021-03-12   675.926026  353.409604\n",
       "30  2021-03-15  1283.485001  611.490786\n",
       "31  2021-03-16  1029.625200  535.180740\n",
       "32  2021-03-17   947.742536  383.400628\n",
       "33  2021-03-18   875.702065  480.292052\n",
       "34  2021-03-19   663.871355  339.274249\n",
       "35  2021-03-22  1231.065855  568.662011\n",
       "36  2021-03-23   991.792657  545.851384\n",
       "37  2021-03-24   885.761741  384.011950\n",
       "38  2021-03-25   817.815692  456.586698\n",
       "39  2021-03-26   599.150994  348.506375\n",
       "40  2021-03-29  1206.596062  543.502074\n",
       "41  2021-03-30   988.283662  524.886447\n",
       "42  2021-03-31   906.483229  378.173363\n",
       "43  2021-04-01   840.787280  445.886445\n",
       "44  2021-04-02   615.540306  343.082918\n",
       "45  2021-04-05  1219.861195  559.839392\n",
       "46  2021-04-06  1030.710767  533.615448\n",
       "47  2021-04-07   915.428950  391.995857\n",
       "48  2021-04-08   892.471322  474.437133\n",
       "49  2021-04-09   613.628739  356.722250"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "junior-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job running time 839.014033 sec\n"
     ]
    }
   ],
   "source": [
    "print('job running time %f sec' % (time.time() - job_start_time ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
